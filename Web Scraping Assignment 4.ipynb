{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8a184f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium import webdriver\n",
    "import requests\n",
    "import re\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ec1342",
   "metadata": {},
   "source": [
    "Q1. Scrape the details of most viewed videos on YouTube from Wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "370e0309",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Surjit Singh Kadian\\Downloads\\chromedriver_win32 (1)\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20fdcd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the webpage of mentioned url \n",
    "url=('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33b78814",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0897904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list for storing data after scraping\n",
    "\n",
    "Rank = []\n",
    "Name = []\n",
    "Artist = []\n",
    "UploadDate = []\n",
    "Views = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3574350d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.',\n",
       " '2.',\n",
       " '3.',\n",
       " '4.',\n",
       " '5.',\n",
       " '6.',\n",
       " '7.',\n",
       " '8.',\n",
       " '9.',\n",
       " '10.',\n",
       " '11.',\n",
       " '12.',\n",
       " '13.',\n",
       " '14.',\n",
       " '15.',\n",
       " '16.',\n",
       " '17.',\n",
       " '18.',\n",
       " '19.',\n",
       " '20.',\n",
       " '21.',\n",
       " '22.',\n",
       " '23.',\n",
       " '24.',\n",
       " '25.',\n",
       " '26.',\n",
       " '27.',\n",
       " '28.',\n",
       " '29.',\n",
       " '30.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping Rank of the videos\n",
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[1]\"):\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append(\"_\")\n",
    "\n",
    "Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eacdc521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"Baby Shark Dance\"[3]',\n",
       " '\"Despacito\"[6]',\n",
       " '\"Johny Johny Yes Papa\"[12]',\n",
       " '\"Shape of You\"[13]',\n",
       " '\"See You Again\"[15]',\n",
       " '\"Bath Song\"[20]',\n",
       " '\"Phonics Song with Two Words\"[21]',\n",
       " '\"Uptown Funk\"[22]',\n",
       " '\"Learning Colors – Colorful Eggs on a Farm\"[23]',\n",
       " '\"Masha and the Bear – Recipe for Disaster\"[24]',\n",
       " '\"Gangnam Style\"[25]',\n",
       " '\"Wheels on the Bus\"[30]',\n",
       " '\"Dame Tu Cosita\"[31]',\n",
       " '\"Sugar\"[32]',\n",
       " '\"Roar\"[33]',\n",
       " '\"Counting Stars\"[34]',\n",
       " '\"Sorry\"[35]',\n",
       " '\"Thinking Out Loud\"[36]',\n",
       " '\"Axel F\"[37]',\n",
       " '\"Girls Like You\"[38]',\n",
       " '\"Faded\"[39]',\n",
       " '\"Dark Horse\"[40]',\n",
       " '\"Baa Baa Black Sheep\"[41]',\n",
       " '\"Let Her Go\"[42]',\n",
       " '\"Bailando\"[43]',\n",
       " '\"Lean On\"[44]',\n",
       " '\"Shake It Off\"[45]',\n",
       " '\"Perfect\"[46]',\n",
       " '\"Waka Waka (This Time for Africa)\"[47]',\n",
       " '\"Mi Gente\"[48]']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraoing Name of the videos\n",
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[2]\"):\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Name.append(\"_\")\n",
    "\n",
    "Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f1a6f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Pinkfong Baby Shark - Kids' Songs & Stories\",\n",
       " 'Luis Fonsi',\n",
       " 'LooLoo Kids',\n",
       " 'Ed Sheeran',\n",
       " 'Wiz Khalifa',\n",
       " 'Cocomelon – Nursery Rhymes',\n",
       " 'ChuChu TV',\n",
       " 'Mark Ronson',\n",
       " 'Miroshka TV',\n",
       " 'Get Movies',\n",
       " 'Psy',\n",
       " 'Cocomelon – Nursery Rhymes',\n",
       " 'El Chombo',\n",
       " 'Maroon 5',\n",
       " 'Katy Perry',\n",
       " 'OneRepublic',\n",
       " 'Justin Bieber',\n",
       " 'Ed Sheeran',\n",
       " 'Crazy Frog',\n",
       " 'Maroon 5',\n",
       " 'Alan Walker',\n",
       " 'Katy Perry',\n",
       " 'Cocomelon – Nursery Rhymes',\n",
       " 'Passenger',\n",
       " 'Enrique Iglesias',\n",
       " 'Major Lazer',\n",
       " 'Taylor Swift',\n",
       " 'Ed Sheeran',\n",
       " 'Shakira',\n",
       " 'J Balvin']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping Artist of the video\n",
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[3]\"):\n",
    "        Artist.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Artist.append(\"_\")\n",
    "Artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50588ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['June 17, 2016',\n",
       " 'January 12, 2017',\n",
       " 'October 8, 2016',\n",
       " 'January 30, 2017',\n",
       " 'April 6, 2015',\n",
       " 'May 2, 2018',\n",
       " 'March 6, 2014',\n",
       " 'November 19, 2014',\n",
       " 'February 27, 2018',\n",
       " 'January 31, 2012',\n",
       " 'July 15, 2012',\n",
       " 'May 24, 2018',\n",
       " 'April 5, 2018',\n",
       " 'January 14, 2015',\n",
       " 'September 5, 2013',\n",
       " 'May 31, 2013',\n",
       " 'October 22, 2015',\n",
       " 'October 7, 2014',\n",
       " 'June 16, 2009',\n",
       " 'May 31, 2018',\n",
       " 'December 3, 2015',\n",
       " 'February 20, 2014',\n",
       " 'June 25, 2018',\n",
       " 'July 25, 2012',\n",
       " 'April 11, 2014',\n",
       " 'March 22, 2015',\n",
       " 'August 18, 2014',\n",
       " 'November 9, 2017',\n",
       " 'June 4, 2010',\n",
       " 'June 29, 2017']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping Uploaded date of the video\n",
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[5]\"):\n",
    "        UploadDate.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    UploadDate.append(\"_\")\n",
    "\n",
    "UploadDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e653f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10.72',\n",
       " '7.85',\n",
       " '6.36',\n",
       " '5.72',\n",
       " '5.52',\n",
       " '5.40',\n",
       " '4.64',\n",
       " '4.58',\n",
       " '4.57',\n",
       " '4.49',\n",
       " '4.43',\n",
       " '4.08',\n",
       " '3.94',\n",
       " '3.69',\n",
       " '3.58',\n",
       " '3.58',\n",
       " '3.54',\n",
       " '3.45',\n",
       " '3.36',\n",
       " '3.29',\n",
       " '3.28',\n",
       " '3.27',\n",
       " '3.24',\n",
       " '3.23',\n",
       " '3.21',\n",
       " '3.21',\n",
       " '3.17',\n",
       " '3.17',\n",
       " '3.14',\n",
       " '3.08']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping Views of videos\n",
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[4]\"):\n",
    "        Views.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Views.append(\"_\")\n",
    "Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63b61dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload Date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Baby Shark Dance</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>10.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>Despacito</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>7.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Johny Johny Yes Papa</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>Shape of You</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>See You Again</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>Bath Song</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>5.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>Phonics Song with Two Words</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>4.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>Uptown Funk</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>Learning Colors – Colorful Eggs on a Farm</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>Masha and the Bear – Recipe for Disaster</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>Gangnam Style</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>Wheels on the Bus</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>4.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>Dame Tu Cosita</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>Sugar</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>Roar</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>Counting Stars</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>Sorry</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>Thinking Out Loud</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>Axel F</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>3.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>Girls Like You</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>Faded</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>Dark Horse</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>Baa Baa Black Sheep</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>Let Her Go</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>Bailando</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>Lean On</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>Shake It Off</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>August 18, 2014</td>\n",
       "      <td>3.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>Perfect</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>Waka Waka (This Time for Africa)</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>Mi Gente</td>\n",
       "      <td>J Balvin</td>\n",
       "      <td>June 29, 2017</td>\n",
       "      <td>3.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                       Name  \\\n",
       "0    1.                           Baby Shark Dance   \n",
       "1    2.                                  Despacito   \n",
       "2    3.                       Johny Johny Yes Papa   \n",
       "3    4.                               Shape of You   \n",
       "4    5.                              See You Again   \n",
       "5    6.                                  Bath Song   \n",
       "6    7.                Phonics Song with Two Words   \n",
       "7    8.                                Uptown Funk   \n",
       "8    9.  Learning Colors – Colorful Eggs on a Farm   \n",
       "9   10.   Masha and the Bear – Recipe for Disaster   \n",
       "10  11.                              Gangnam Style   \n",
       "11  12.                          Wheels on the Bus   \n",
       "12  13.                             Dame Tu Cosita   \n",
       "13  14.                                      Sugar   \n",
       "14  15.                                       Roar   \n",
       "15  16.                             Counting Stars   \n",
       "16  17.                                      Sorry   \n",
       "17  18.                          Thinking Out Loud   \n",
       "18  19.                                     Axel F   \n",
       "19  20.                             Girls Like You   \n",
       "20  21.                                      Faded   \n",
       "21  22.                                 Dark Horse   \n",
       "22  23.                        Baa Baa Black Sheep   \n",
       "23  24.                                 Let Her Go   \n",
       "24  25.                                   Bailando   \n",
       "25  26.                                    Lean On   \n",
       "26  27.                               Shake It Off   \n",
       "27  28.                                    Perfect   \n",
       "28  29.           Waka Waka (This Time for Africa)   \n",
       "29  30.                                   Mi Gente   \n",
       "\n",
       "                                         Artist        Upload Date  Views  \n",
       "0   Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016  10.72  \n",
       "1                                    Luis Fonsi   January 12, 2017   7.85  \n",
       "2                                   LooLoo Kids    October 8, 2016   6.36  \n",
       "3                                    Ed Sheeran   January 30, 2017   5.72  \n",
       "4                                   Wiz Khalifa      April 6, 2015   5.52  \n",
       "5                    Cocomelon – Nursery Rhymes        May 2, 2018   5.40  \n",
       "6                                     ChuChu TV      March 6, 2014   4.64  \n",
       "7                                   Mark Ronson  November 19, 2014   4.58  \n",
       "8                                   Miroshka TV  February 27, 2018   4.57  \n",
       "9                                    Get Movies   January 31, 2012   4.49  \n",
       "10                                          Psy      July 15, 2012   4.43  \n",
       "11                   Cocomelon – Nursery Rhymes       May 24, 2018   4.08  \n",
       "12                                    El Chombo      April 5, 2018   3.94  \n",
       "13                                     Maroon 5   January 14, 2015   3.69  \n",
       "14                                   Katy Perry  September 5, 2013   3.58  \n",
       "15                                  OneRepublic       May 31, 2013   3.58  \n",
       "16                                Justin Bieber   October 22, 2015   3.54  \n",
       "17                                   Ed Sheeran    October 7, 2014   3.45  \n",
       "18                                   Crazy Frog      June 16, 2009   3.36  \n",
       "19                                     Maroon 5       May 31, 2018   3.29  \n",
       "20                                  Alan Walker   December 3, 2015   3.28  \n",
       "21                                   Katy Perry  February 20, 2014   3.27  \n",
       "22                   Cocomelon – Nursery Rhymes      June 25, 2018   3.24  \n",
       "23                                    Passenger      July 25, 2012   3.23  \n",
       "24                             Enrique Iglesias     April 11, 2014   3.21  \n",
       "25                                  Major Lazer     March 22, 2015   3.21  \n",
       "26                                 Taylor Swift    August 18, 2014   3.17  \n",
       "27                                   Ed Sheeran   November 9, 2017   3.17  \n",
       "28                                      Shakira       June 4, 2010   3.14  \n",
       "29                                     J Balvin      June 29, 2017   3.08  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame from scraped data\n",
    "Wiki = pd.DataFrame({})\n",
    "Wiki['Rank']=Rank\n",
    "Wiki['Name']=Name\n",
    "Wiki['Artist']=Artist\n",
    "Wiki['Upload Date']=UploadDate\n",
    "Wiki['Views']=Views\n",
    "\n",
    "# Removing stray numbers from Name column\n",
    "Wiki.Name = Wiki.Name.apply(lambda x:x[:-4].strip('\"'))\n",
    "Wiki"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c1720f",
   "metadata": {},
   "source": [
    "Q2. Scrape the details team India’s international fixtures from bcci.tv.\n",
    "\n",
    "Url = https://www.bcci.tv/.\n",
    "\n",
    "You need to find following details:\n",
    "\n",
    "A) Match title (I.e. 1\n",
    "\n",
    "st ODI)\n",
    "\n",
    "B) Series\n",
    "\n",
    "C) Place\n",
    "\n",
    "D) Date\n",
    "\n",
    "E) Time\n",
    "\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "5f0d1ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the webpage of mentioned url\n",
    "url1 = 'https://www.bcci.tv/'              \n",
    "driver.get(url1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "364bb5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on international, SO that I can reach on the required page, from where I have to extract the data.\n",
    "international = driver.find_element_by_xpath('//li[@class=\"nav-item\"]/a')  \n",
    "international.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7ea28306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "series = []             # Giving the empty list for all the coloumn, what all I want to extract\n",
    "odi = [] \n",
    "date = []\n",
    "time = []\n",
    "place = []\n",
    "     \n",
    "ser = driver.find_elements_by_xpath('//h5[@class=\"fix-text\"][2]/span')            #Giving the xpath of the required data what I want to extract\n",
    "od = driver.find_elements_by_xpath('//div[@class=\"fix-place ng-binding ng-scope\"]/span[1]')\n",
    "da = driver.find_elements_by_xpath('//div[@class=\"match-card-left match-schedule\"]')\n",
    "ti = driver.find_elements_by_xpath('//div[@class=\"match-card-right match-schedule \"]')\n",
    "pla = driver.find_elements_by_xpath('//div[@class=\"fix-place ng-binding ng-scope\"]/span[2]')\n",
    "\n",
    "for i in ser:\n",
    "    series.append(i.text)                    # Appending the text data\n",
    "for j in od:\n",
    "    odi.append(j.text.replace('-',''))\n",
    "for k in da:\n",
    "    date.append(k.text)\n",
    "for l in ti:\n",
    "    time.append(l.text)\n",
    "for m in pla:\n",
    "    place.append(m.text)\n",
    "    \n",
    "print(len(series))            # Printing the length of the all the data what, I have extracted\n",
    "print(len(odi))\n",
    "print(len(date))\n",
    "print(len(time))\n",
    "print(len(place))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "01844831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>Dr YS Rajasekhara Reddy ACA-VDCA Cricket Stadium,</td>\n",
       "      <td>14 JUN 2022</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4th T20I</td>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>Saurashtra Cricket Association Stadium,</td>\n",
       "      <td>17 JUN 2022</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5th T20I</td>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>M Chinnaswamy Stadium,</td>\n",
       "      <td>19 JUN 2022</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Match Title                                      Series  \\\n",
       "0   3rd T20I   SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022   \n",
       "1   4th T20I   SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022   \n",
       "2   5th T20I   SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022   \n",
       "\n",
       "                                               Place         Date         time  \n",
       "0  Dr YS Rajasekhara Reddy ACA-VDCA Cricket Stadium,  14 JUN 2022  7:00 PM IST  \n",
       "1            Saurashtra Cricket Association Stadium,  17 JUN 2022  7:00 PM IST  \n",
       "2                             M Chinnaswamy Stadium,  19 JUN 2022  7:00 PM IST  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame from scraped data\n",
    "df = pd.DataFrame({'Match Title':odi,\n",
    "                   'Series':series,\n",
    "                   'Place':place,\n",
    "                   'Date':date,\n",
    "                   'time':time})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ec4900",
   "metadata": {},
   "source": [
    "Q3.. Scrape the details of selenium exception from guru99.com.\n",
    "\n",
    "Url = https://www.guru99.com/\n",
    "\n",
    "You need to find following details:\n",
    "\n",
    "A) Name\n",
    "\n",
    "B) Description\n",
    "\n",
    "Note: - From guru99 home page you have to reach to selenium exception handling page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "818c6b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the webpage of mentioned url \n",
    "url=('https://www.guru99.com/')\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44869eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1745bfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list\n",
    "Name = []\n",
    "Description = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b65e903",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on Selenium button\n",
    "driver.find_element_by_xpath(\"//li//a[@title='Selenium']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d9080eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on Exception Handling button\n",
    "driver.find_element_by_xpath('//a[@title=\"Selenium Exception Handling (Common Exceptions List)\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "726468f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ElementNotVisibleException',\n",
       " 'ElementNotSelectableException',\n",
       " 'NoSuchElementException',\n",
       " 'NoSuchFrameException',\n",
       " 'NoAlertPresentException',\n",
       " 'NoSuchWindowException',\n",
       " 'StaleElementReferenceException',\n",
       " 'SessionNotFoundException',\n",
       " 'TimeoutException',\n",
       " 'WebDriverException',\n",
       " 'ConnectionClosedException',\n",
       " 'ElementClickInterceptedException',\n",
       " 'ElementNotInteractableException',\n",
       " 'ErrorInResponseException',\n",
       " 'ErrorHandler.UnknownServerException',\n",
       " 'ImeActivationFailedException',\n",
       " 'ImeNotAvailableException',\n",
       " 'InsecureCertificateException',\n",
       " 'InvalidArgumentException',\n",
       " 'InvalidCookieDomainException',\n",
       " 'InvalidCoordinatesException',\n",
       " 'InvalidElementStateExceptio',\n",
       " 'InvalidSessionIdException',\n",
       " 'InvalidSwitchToTargetException',\n",
       " 'JavascriptException',\n",
       " 'JsonException',\n",
       " 'NoSuchAttributeException',\n",
       " 'MoveTargetOutOfBoundsException',\n",
       " 'NoSuchContextException',\n",
       " 'NoSuchCookieException',\n",
       " 'NotFoundException',\n",
       " 'RemoteDriverServerException',\n",
       " 'ScreenshotException',\n",
       " 'SessionNotCreatedException',\n",
       " 'UnableToSetCookieException',\n",
       " 'UnexpectedTagNameException',\n",
       " 'UnhandledAlertException',\n",
       " 'UnexpectedAlertPresentException',\n",
       " 'UnknownMethodException',\n",
       " 'UnreachableBrowserException',\n",
       " 'UnsupportedCommandException']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scraping Name\n",
    "for i in driver.find_elements_by_xpath(\"//table[@class='table table-striped']/tbody/tr/td[1]\"):\n",
    "            Name.append(i.text)\n",
    "Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e9a0ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This type of Selenium exception occurs when an existing element in DOM has a feature set as hidden.',\n",
       " 'This Selenium exception occurs when an element is presented in the DOM, but you can be able to select. Therefore, it is not possible to interact.',\n",
       " 'This Exception occurs if an element could not be found.',\n",
       " 'This Exception occurs if the frame target to be switched to does not exist.',\n",
       " 'This Exception occurs when you switch to no presented alert.',\n",
       " 'This Exception occurs if the window target to be switch does not exist.',\n",
       " 'This Selenium exception occurs happens when the web element is detached from the current DOM.',\n",
       " 'The WebDriver is acting after you quit the browser.',\n",
       " 'Thrown when there is not enough time for a command to be completed. For Example, the element searched wasn’t found in the specified time.',\n",
       " 'This Exception takes place when the WebDriver is acting right after you close the browser.',\n",
       " 'This type of Exception takes place when there is a disconnection in the driver.',\n",
       " 'The command may not be completed as the element receiving the events is concealing the element which was requested clicked.',\n",
       " 'This Selenium exception is thrown when any element is presented in the DOM. However, it is impossible to interact with such an element.',\n",
       " 'This happens while interacting with the Firefox extension or the remote driver server.',\n",
       " 'Exception is used as a placeholder in case if the server returns an error without a stack trace.',\n",
       " 'This expectation will occur when IME engine activation has failed.',\n",
       " 'It takes place when IME support is unavailable.',\n",
       " 'Navigation made the user agent to hit a certificate warning. This can cause by an invalid or expired TLS certificate.',\n",
       " 'It occurs when an argument does not belong to the expected type.',\n",
       " 'This happens when you try to add a cookie under a different domain instead of current URL.',\n",
       " 'This type of Exception matches an interacting operation that is not valid.',\n",
       " 'It occurs when command can’t be finished when the element is invalid.',\n",
       " 'This Exception took place when the given session ID is not included in the list of active sessions. It means the session does not exist or is inactive either.',\n",
       " 'This occurs when the frame or window target to be switched does not exist.',\n",
       " 'This issue occurs while executing JavaScript given by the user.',\n",
       " 'It occurs when you afford to get the session when the session is not created.',\n",
       " 'This kind of Exception occurs when the attribute of an element could not be found.',\n",
       " 'It takes place if the target provided to the ActionChains move() methodology is not valid. For Example, out of the document.',\n",
       " 'ContextAware does mobile device testing.',\n",
       " 'This Exception occurs when no cookie matching with the given pathname found for all the associated cookies of the currently browsing document.',\n",
       " 'This Exception is a subclass of WebDriverException. This will occur when an element on the DOM does not exist.',\n",
       " 'This Selenium exception is thrown when the server is not responding because of the problem that the capabilities described are not proper.',\n",
       " 'It is not possible to capture a screen.',\n",
       " 'It happens when a new session could not be successfully created.',\n",
       " 'This occurs if a driver is unable to set a cookie.',\n",
       " 'Happens if a support class did not get a web element as expected.',\n",
       " 'This expectation occurs when there is an alert, but WebDriver is not able to perform Alert operation.',\n",
       " 'It occurs when there is the appearance of an unexpected alert.',\n",
       " 'This Exception happens when the requested command matches with a known URL but and not matching with a methodology for a specific URL.',\n",
       " 'This Exception occurs only when the browser is not able to be opened or crashed because of some reason.',\n",
       " 'This occurs when remote WebDriver does n’t send valid commands as expected.']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scraping Description\n",
    "for i in driver.find_elements_by_xpath(\"//table[@class='table table-striped']/tbody/tr/td[2]\"):\n",
    "            Description.append(i.text)\n",
    "Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9917f8ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exception_Name</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ElementNotVisibleException</td>\n",
       "      <td>This type of Selenium exception occurs when an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ElementNotSelectableException</td>\n",
       "      <td>This Selenium exception occurs when an element...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NoSuchElementException</td>\n",
       "      <td>This Exception occurs if an element could not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NoSuchFrameException</td>\n",
       "      <td>This Exception occurs if the frame target to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NoAlertPresentException</td>\n",
       "      <td>This Exception occurs when you switch to no pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NoSuchWindowException</td>\n",
       "      <td>This Exception occurs if the window target to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>StaleElementReferenceException</td>\n",
       "      <td>This Selenium exception occurs happens when th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SessionNotFoundException</td>\n",
       "      <td>The WebDriver is acting after you quit the bro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TimeoutException</td>\n",
       "      <td>Thrown when there is not enough time for a com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WebDriverException</td>\n",
       "      <td>This Exception takes place when the WebDriver ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ConnectionClosedException</td>\n",
       "      <td>This type of Exception takes place when there ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ElementClickInterceptedException</td>\n",
       "      <td>The command may not be completed as the elemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ElementNotInteractableException</td>\n",
       "      <td>This Selenium exception is thrown when any ele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ErrorInResponseException</td>\n",
       "      <td>This happens while interacting with the Firefo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ErrorHandler.UnknownServerException</td>\n",
       "      <td>Exception is used as a placeholder in case if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ImeActivationFailedException</td>\n",
       "      <td>This expectation will occur when IME engine ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ImeNotAvailableException</td>\n",
       "      <td>It takes place when IME support is unavailable.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>InsecureCertificateException</td>\n",
       "      <td>Navigation made the user agent to hit a certif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>InvalidArgumentException</td>\n",
       "      <td>It occurs when an argument does not belong to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>InvalidCookieDomainException</td>\n",
       "      <td>This happens when you try to add a cookie unde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>InvalidCoordinatesException</td>\n",
       "      <td>This type of Exception matches an interacting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>InvalidElementStateExceptio</td>\n",
       "      <td>It occurs when command can’t be finished when ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>InvalidSessionIdException</td>\n",
       "      <td>This Exception took place when the given sessi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>InvalidSwitchToTargetException</td>\n",
       "      <td>This occurs when the frame or window target to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>JavascriptException</td>\n",
       "      <td>This issue occurs while executing JavaScript g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>JsonException</td>\n",
       "      <td>It occurs when you afford to get the session w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NoSuchAttributeException</td>\n",
       "      <td>This kind of Exception occurs when the attribu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>MoveTargetOutOfBoundsException</td>\n",
       "      <td>It takes place if the target provided to the A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NoSuchContextException</td>\n",
       "      <td>ContextAware does mobile device testing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NoSuchCookieException</td>\n",
       "      <td>This Exception occurs when no cookie matching ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NotFoundException</td>\n",
       "      <td>This Exception is a subclass of WebDriverExcep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>RemoteDriverServerException</td>\n",
       "      <td>This Selenium exception is thrown when the ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ScreenshotException</td>\n",
       "      <td>It is not possible to capture a screen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SessionNotCreatedException</td>\n",
       "      <td>It happens when a new session could not be suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>UnableToSetCookieException</td>\n",
       "      <td>This occurs if a driver is unable to set a coo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>UnexpectedTagNameException</td>\n",
       "      <td>Happens if a support class did not get a web e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>UnhandledAlertException</td>\n",
       "      <td>This expectation occurs when there is an alert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>UnexpectedAlertPresentException</td>\n",
       "      <td>It occurs when there is the appearance of an u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>UnknownMethodException</td>\n",
       "      <td>This Exception happens when the requested comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>UnreachableBrowserException</td>\n",
       "      <td>This Exception occurs only when the browser is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>UnsupportedCommandException</td>\n",
       "      <td>This occurs when remote WebDriver does n’t sen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Exception_Name  \\\n",
       "0            ElementNotVisibleException   \n",
       "1         ElementNotSelectableException   \n",
       "2                NoSuchElementException   \n",
       "3                  NoSuchFrameException   \n",
       "4               NoAlertPresentException   \n",
       "5                 NoSuchWindowException   \n",
       "6        StaleElementReferenceException   \n",
       "7              SessionNotFoundException   \n",
       "8                      TimeoutException   \n",
       "9                    WebDriverException   \n",
       "10            ConnectionClosedException   \n",
       "11     ElementClickInterceptedException   \n",
       "12      ElementNotInteractableException   \n",
       "13             ErrorInResponseException   \n",
       "14  ErrorHandler.UnknownServerException   \n",
       "15         ImeActivationFailedException   \n",
       "16             ImeNotAvailableException   \n",
       "17         InsecureCertificateException   \n",
       "18             InvalidArgumentException   \n",
       "19         InvalidCookieDomainException   \n",
       "20          InvalidCoordinatesException   \n",
       "21          InvalidElementStateExceptio   \n",
       "22            InvalidSessionIdException   \n",
       "23       InvalidSwitchToTargetException   \n",
       "24                  JavascriptException   \n",
       "25                        JsonException   \n",
       "26             NoSuchAttributeException   \n",
       "27       MoveTargetOutOfBoundsException   \n",
       "28               NoSuchContextException   \n",
       "29                NoSuchCookieException   \n",
       "30                    NotFoundException   \n",
       "31          RemoteDriverServerException   \n",
       "32                  ScreenshotException   \n",
       "33           SessionNotCreatedException   \n",
       "34           UnableToSetCookieException   \n",
       "35           UnexpectedTagNameException   \n",
       "36              UnhandledAlertException   \n",
       "37      UnexpectedAlertPresentException   \n",
       "38               UnknownMethodException   \n",
       "39          UnreachableBrowserException   \n",
       "40          UnsupportedCommandException   \n",
       "\n",
       "                                          Description  \n",
       "0   This type of Selenium exception occurs when an...  \n",
       "1   This Selenium exception occurs when an element...  \n",
       "2   This Exception occurs if an element could not ...  \n",
       "3   This Exception occurs if the frame target to b...  \n",
       "4   This Exception occurs when you switch to no pr...  \n",
       "5   This Exception occurs if the window target to ...  \n",
       "6   This Selenium exception occurs happens when th...  \n",
       "7   The WebDriver is acting after you quit the bro...  \n",
       "8   Thrown when there is not enough time for a com...  \n",
       "9   This Exception takes place when the WebDriver ...  \n",
       "10  This type of Exception takes place when there ...  \n",
       "11  The command may not be completed as the elemen...  \n",
       "12  This Selenium exception is thrown when any ele...  \n",
       "13  This happens while interacting with the Firefo...  \n",
       "14  Exception is used as a placeholder in case if ...  \n",
       "15  This expectation will occur when IME engine ac...  \n",
       "16    It takes place when IME support is unavailable.  \n",
       "17  Navigation made the user agent to hit a certif...  \n",
       "18  It occurs when an argument does not belong to ...  \n",
       "19  This happens when you try to add a cookie unde...  \n",
       "20  This type of Exception matches an interacting ...  \n",
       "21  It occurs when command can’t be finished when ...  \n",
       "22  This Exception took place when the given sessi...  \n",
       "23  This occurs when the frame or window target to...  \n",
       "24  This issue occurs while executing JavaScript g...  \n",
       "25  It occurs when you afford to get the session w...  \n",
       "26  This kind of Exception occurs when the attribu...  \n",
       "27  It takes place if the target provided to the A...  \n",
       "28           ContextAware does mobile device testing.  \n",
       "29  This Exception occurs when no cookie matching ...  \n",
       "30  This Exception is a subclass of WebDriverExcep...  \n",
       "31  This Selenium exception is thrown when the ser...  \n",
       "32            It is not possible to capture a screen.  \n",
       "33  It happens when a new session could not be suc...  \n",
       "34  This occurs if a driver is unable to set a coo...  \n",
       "35  Happens if a support class did not get a web e...  \n",
       "36  This expectation occurs when there is an alert...  \n",
       "37  It occurs when there is the appearance of an u...  \n",
       "38  This Exception happens when the requested comm...  \n",
       "39  This Exception occurs only when the browser is...  \n",
       "40  This occurs when remote WebDriver does n’t sen...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the dataframe from the scraped data\n",
    "Selenium=pd.DataFrame({})\n",
    "Selenium['Exception_Name']=Name\n",
    "Selenium['Description']=Description\n",
    "Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5b4932",
   "metadata": {},
   "source": [
    "Q4. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "\n",
    "Url = http://statisticstimes.com/\n",
    "\n",
    "You have to find following details:\n",
    "\n",
    "A) Rank\n",
    "\n",
    "B) State\n",
    "\n",
    "C) GSDP(18-19)\n",
    "\n",
    "D) GSDP(17-18)\n",
    "\n",
    "E) Share(2017)\n",
    "\n",
    "F) GDP($ billion)\n",
    "\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "77ac687f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Surjit Singh Kadian\\Downloads\\chromedriver_win32 (1)\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f5f9e6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the webpage of mentioned url \n",
    "url=('http://statisticstimes.com/')\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b2846d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "26191eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "economy = driver.find_element_by_xpath('/html/body/div[2]/div[1]/div[2]/div[2]/button')       #Giving the Xpath\n",
    "economy.click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8fdb7ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "india = driver.find_element_by_xpath('/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]')\n",
    "india.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6589f305",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp = driver.find_element_by_xpath('/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')\n",
    "gdp.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "175821f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list\n",
    "Rank = []\n",
    "State = []\n",
    "GSDP1 = []\n",
    "GSDP2 = []\n",
    "Share = []\n",
    "GDPbillion = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "25792a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '20',\n",
       " '21',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '25',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '30',\n",
       " '31',\n",
       " '32',\n",
       " '33',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '20',\n",
       " '21',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '25',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '30',\n",
       " '31',\n",
       " '32',\n",
       " '33']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping Rank\n",
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//table[@class='display dataTable']/tbody/tr/td[1]\"):\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append(\"_\")\n",
    "Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e655790a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping State\n",
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//table[@class='display dataTable']/tbody/tr/td[2]\"):\n",
    "        State.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    State.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "be150d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Maharashtra',\n",
       " 'Tamil Nadu',\n",
       " 'Uttar Pradesh',\n",
       " 'Gujarat',\n",
       " 'Karnataka',\n",
       " 'West Bengal',\n",
       " 'Rajasthan',\n",
       " 'Andhra Pradesh',\n",
       " 'Telangana',\n",
       " 'Madhya Pradesh',\n",
       " 'Kerala',\n",
       " 'Delhi',\n",
       " 'Haryana',\n",
       " 'Bihar',\n",
       " 'Punjab',\n",
       " 'Odisha',\n",
       " 'Assam',\n",
       " 'Chhattisgarh',\n",
       " 'Jharkhand',\n",
       " 'Uttarakhand',\n",
       " 'Jammu & Kashmir',\n",
       " 'Himachal Pradesh',\n",
       " 'Goa',\n",
       " 'Tripura',\n",
       " 'Chandigarh',\n",
       " 'Puducherry',\n",
       " 'Meghalaya',\n",
       " 'Sikkim',\n",
       " 'Manipur',\n",
       " 'Nagaland',\n",
       " 'Arunachal Pradesh',\n",
       " 'Mizoram',\n",
       " 'Andaman & Nicobar Islands',\n",
       " 'Maharashtra',\n",
       " 'Tamil Nadu',\n",
       " 'Uttar Pradesh',\n",
       " 'Karnataka',\n",
       " 'Gujarat',\n",
       " 'West Bengal',\n",
       " 'Rajasthan',\n",
       " 'Telangana',\n",
       " 'Andhra Pradesh',\n",
       " 'Madhya Pradesh',\n",
       " 'Kerala',\n",
       " 'Delhi',\n",
       " 'Haryana',\n",
       " 'Bihar',\n",
       " 'Punjab',\n",
       " 'Odisha',\n",
       " 'Assam',\n",
       " 'Jharkhand',\n",
       " 'Chhattisgarh',\n",
       " 'Uttarakhand',\n",
       " 'Himachal Pradesh',\n",
       " 'Jammu & Kashmir',\n",
       " 'Goa',\n",
       " 'Tripura',\n",
       " 'Chandigarh',\n",
       " 'Puducherry',\n",
       " 'Meghalaya',\n",
       " 'Manipur',\n",
       " 'Sikkim',\n",
       " 'Nagaland',\n",
       " 'Arunachal Pradesh',\n",
       " 'Mizoram',\n",
       " 'Andaman & Nicobar Islands']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2f0d5ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-',\n",
       " '1,845,853',\n",
       " '1,687,818',\n",
       " '-',\n",
       " '1,631,977',\n",
       " '1,253,832',\n",
       " '1,020,989',\n",
       " '972,782',\n",
       " '969,604',\n",
       " '906,672',\n",
       " '-',\n",
       " '856,112',\n",
       " '831,610',\n",
       " '611,804',\n",
       " '574,760',\n",
       " '521,275',\n",
       " '-',\n",
       " '329,180',\n",
       " '328,598',\n",
       " '-',\n",
       " '-',\n",
       " '165,472',\n",
       " '80,449',\n",
       " '55,984',\n",
       " '-',\n",
       " '38,253',\n",
       " '36,572',\n",
       " '32,496',\n",
       " '31,790',\n",
       " '-',\n",
       " '-',\n",
       " '26,503',\n",
       " '-',\n",
       " '-',\n",
       " '1,659,210',\n",
       " '1,495,758',\n",
       " '1,476,983',\n",
       " '-',\n",
       " '1,150,711',\n",
       " '916,014',\n",
       " '881,873',\n",
       " '875,429',\n",
       " '827,019',\n",
       " '-',\n",
       " '779,647',\n",
       " '755,790',\n",
       " '562,710',\n",
       " '517,521',\n",
       " '457,757',\n",
       " '-',\n",
       " '301,242',\n",
       " '288,041',\n",
       " '-',\n",
       " '143,063',\n",
       " '-',\n",
       " '72,181',\n",
       " '50,227',\n",
       " '-',\n",
       " '34,823',\n",
       " '32,833',\n",
       " '29,148',\n",
       " '28,391',\n",
       " '-',\n",
       " '-',\n",
       " '24,424',\n",
       " '-']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping GSDP at current price (19-20)\n",
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//table[@class='display dataTable']/tbody/tr/td[3]\"):\n",
    "        GSDP1.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP1.append(\"_\")\n",
    "GSDP1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dc1fa86c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,632,792',\n",
       " '1,630,208',\n",
       " '1,584,764',\n",
       " '1,502,899',\n",
       " '1,493,127',\n",
       " '1,089,898',\n",
       " '942,586',\n",
       " '862,957',\n",
       " '861,031',\n",
       " '809,592',\n",
       " '781,653',\n",
       " '774,870',\n",
       " '734,163',\n",
       " '530,363',\n",
       " '526,376',\n",
       " '487,805',\n",
       " '315,881',\n",
       " '304,063',\n",
       " '297,204',\n",
       " '245,895',\n",
       " '155,956',\n",
       " '153,845',\n",
       " '73,170',\n",
       " '49,845',\n",
       " '42,114',\n",
       " '34,433',\n",
       " '33,481',\n",
       " '28,723',\n",
       " '27,870',\n",
       " '27,283',\n",
       " '24,603',\n",
       " '22,287',\n",
       " '-',\n",
       " '2,332,992',\n",
       " '1,465,361',\n",
       " '1,404,761',\n",
       " '1,351,553',\n",
       " '1,322,936',\n",
       " '995,502',\n",
       " '845,247',\n",
       " '782,370',\n",
       " '776,140',\n",
       " '737,156',\n",
       " '707,542',\n",
       " '704,529',\n",
       " '666,075',\n",
       " '486,776',\n",
       " '472,506',\n",
       " '428,031',\n",
       " '282,782',\n",
       " '271,990',\n",
       " '266,537',\n",
       " '221,871',\n",
       " '133,303',\n",
       " '129,877',\n",
       " '66,060',\n",
       " '44,835',\n",
       " '37,571',\n",
       " '31,415',\n",
       " '29,544',\n",
       " '25,323',\n",
       " '25,141',\n",
       " '24,534',\n",
       " '22,488',\n",
       " '20,947',\n",
       " '-']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping GSDP at current price (18-19)\n",
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//table[@class='display dataTable']/tbody/tr/td[4]\"):\n",
    "        GSDP2.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP2.append(\"_\")\n",
    "GSDP2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e9aa5a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['13.94%',\n",
       " '8.63%',\n",
       " '8.39%',\n",
       " '7.96%',\n",
       " '7.91%',\n",
       " '5.77%',\n",
       " '4.99%',\n",
       " '4.57%',\n",
       " '4.56%',\n",
       " '4.29%',\n",
       " '4.14%',\n",
       " '4.10%',\n",
       " '3.89%',\n",
       " '2.81%',\n",
       " '2.79%',\n",
       " '2.58%',\n",
       " '1.67%',\n",
       " '1.61%',\n",
       " '1.57%',\n",
       " '1.30%',\n",
       " '0.83%',\n",
       " '0.81%',\n",
       " '0.39%',\n",
       " '0.26%',\n",
       " '0.22%',\n",
       " '0.18%',\n",
       " '0.18%',\n",
       " '0.15%',\n",
       " '0.15%',\n",
       " '0.14%',\n",
       " '0.13%',\n",
       " '0.12%',\n",
       " '-',\n",
       " '13.97%',\n",
       " '8.77%',\n",
       " '8.41%',\n",
       " '8.09%',\n",
       " '7.92%',\n",
       " '5.96%',\n",
       " '5.06%',\n",
       " '4.68%',\n",
       " '4.65%',\n",
       " '4.41%',\n",
       " '4.24%',\n",
       " '4.22%',\n",
       " '3.99%',\n",
       " '2.91%',\n",
       " '2.83%',\n",
       " '2.56%',\n",
       " '1.69%',\n",
       " '1.63%',\n",
       " '1.60%',\n",
       " '1.33%',\n",
       " '0.80%',\n",
       " '0.78%',\n",
       " '0.40%',\n",
       " '0.27%',\n",
       " '0.22%',\n",
       " '0.19%',\n",
       " '0.18%',\n",
       " '0.15%',\n",
       " '0.15%',\n",
       " '0.15%',\n",
       " '0.13%',\n",
       " '0.13%',\n",
       " '-']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping Share (18-19)\n",
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//table[@class='display dataTable']/tbody/tr/td[5]\"):\n",
    "        Share.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Share.append(\"_\")\n",
    "Share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "10452edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['399.921',\n",
       " '247.629',\n",
       " '240.726',\n",
       " '228.290',\n",
       " '226.806',\n",
       " '165.556',\n",
       " '143.179',\n",
       " '131.083',\n",
       " '130.791',\n",
       " '122.977',\n",
       " '118.733',\n",
       " '117.703',\n",
       " '111.519',\n",
       " '80.562',\n",
       " '79.957',\n",
       " '74.098',\n",
       " '47.982',\n",
       " '46.187',\n",
       " '45.145',\n",
       " '37.351',\n",
       " '23.690',\n",
       " '23.369',\n",
       " '11.115',\n",
       " '7.571',\n",
       " '6.397',\n",
       " '5.230',\n",
       " '5.086',\n",
       " '4.363',\n",
       " '4.233',\n",
       " '4.144',\n",
       " '3.737',\n",
       " '3.385',\n",
       " '-',\n",
       " '-',\n",
       " '1,167,776',\n",
       " '1,015,735',\n",
       " '1,035,131',\n",
       " '-',\n",
       " '713,376',\n",
       " '630,693',\n",
       " '594,806',\n",
       " '595,605',\n",
       " '496,798',\n",
       " '-',\n",
       " '568,265',\n",
       " '514,983',\n",
       " '377,276',\n",
       " '374,015',\n",
       " '344,437',\n",
       " '-',\n",
       " '218,232',\n",
       " '210,837',\n",
       " '-',\n",
       " '107,171',\n",
       " '-',\n",
       " '56,810',\n",
       " '35,980',\n",
       " '-',\n",
       " '22,291',\n",
       " '23,564',\n",
       " '18,549',\n",
       " '17,060',\n",
       " '-',\n",
       " '-',\n",
       " '17,797',\n",
       " '-']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping GDP $ billion\n",
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//table[@class='display dataTable']/tbody/tr/td[6]\"):\n",
    "        GDPbillion.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GDPbillion.append(\"_\")\n",
    "GDPbillion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "93809e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP at current price (19-20)</th>\n",
       "      <th>GSDP at current price (18-19)</th>\n",
       "      <th>Share(18-19)</th>\n",
       "      <th>GDP($ billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>29</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>28,391</td>\n",
       "      <td>25,141</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>17,060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>24,534</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>22,488</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>24,424</td>\n",
       "      <td>20,947</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>17,797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP at current price (19-20)  \\\n",
       "0     1                Maharashtra                             -   \n",
       "1     2                 Tamil Nadu                     1,845,853   \n",
       "2     3              Uttar Pradesh                     1,687,818   \n",
       "3     4                    Gujarat                             -   \n",
       "4     5                  Karnataka                     1,631,977   \n",
       "..  ...                        ...                           ...   \n",
       "61   29                     Sikkim                        28,391   \n",
       "62   30                   Nagaland                             -   \n",
       "63   31          Arunachal Pradesh                             -   \n",
       "64   32                    Mizoram                        24,424   \n",
       "65   33  Andaman & Nicobar Islands                             -   \n",
       "\n",
       "   GSDP at current price (18-19) Share(18-19)  GDP($ billion)  \n",
       "0                      2,632,792       13.94%         399.921  \n",
       "1                      1,630,208        8.63%         247.629  \n",
       "2                      1,584,764        8.39%         240.726  \n",
       "3                      1,502,899        7.96%         228.290  \n",
       "4                      1,493,127        7.91%         226.806  \n",
       "..                           ...          ...             ...  \n",
       "61                        25,141        0.15%          17,060  \n",
       "62                        24,534        0.15%               -  \n",
       "63                        22,488        0.13%               -  \n",
       "64                        20,947        0.13%          17,797  \n",
       "65                             -            -               -  \n",
       "\n",
       "[66 rows x 6 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame from the scraped data\n",
    "GDP = pd.DataFrame({})\n",
    "GDP['Rank'] = Rank\n",
    "GDP['State'] = State\n",
    "GDP['GSDP at current price (19-20)'] = GSDP1\n",
    "GDP['GSDP at current price (18-19)'] = GSDP2\n",
    "GDP['Share(18-19)'] = Share\n",
    "GDP[' GDP($ billion)'] = GDPbillion\n",
    "GDP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468def9d",
   "metadata": {},
   "source": [
    "Q5: Scrape the details of trending repositories on Github.com.\n",
    "\n",
    "Url = https://github.com/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Repository title\n",
    "\n",
    "B) Repository description\n",
    "\n",
    "C) Contributors count\n",
    "\n",
    "D) Language used\n",
    "\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "10f2c5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the webpage of mentioned url \n",
    "url=('https://github.com/')\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1fcc05c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting explore button and clicking on it\n",
    "explore = driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "900283b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting trending option\n",
    "trend_url = driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/div/ul/li[5]/a\")\n",
    "urls = trend_url.get_attribute(\"href\")\n",
    "driver.get(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fcc0a3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty list\n",
    "#Creating empty list\n",
    "URLs = []\n",
    "repository_title = []\n",
    "Description = []\n",
    "Contributors = []\n",
    "Language = []\n",
    "lang = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "82277447",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetching urls for each repository\n",
    "repository = driver.find_elements_by_xpath(\"//h1[@class = 'h3 lh-condensed']//a\")\n",
    "for i in repository:\n",
    "    URLs.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "aed005ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['atom / atom',\n",
       " 'saharmor / dalle-playground',\n",
       " 'borisdayma / dalle-mini',\n",
       " 'openai / DALL-E',\n",
       " 'microsoft / Data-Science-For-Beginners',\n",
       " 'microsoft / ML-For-Beginners',\n",
       " 'papers-we-love / papers-we-love',\n",
       " 'vaxerski / Hyprland',\n",
       " 'NVlabs / eg3d',\n",
       " 'microsoft / Web-Dev-For-Beginners',\n",
       " 'PaperMC / Paper',\n",
       " 'lapce / lapce',\n",
       " 'RasaHQ / rasa',\n",
       " 'CyC2018 / CS-Notes',\n",
       " 'tvbb / z',\n",
       " 'ahmedtariq01 / Cloud-DevOps-Learning-Resources',\n",
       " 'digitalocean / nginxconfig.io',\n",
       " 'jina-ai / dalle-flow',\n",
       " 'deepkit / deepkit-framework',\n",
       " 'shimohq / chinese-programmer-wrong-pronunciation',\n",
       " 'facebook / folly',\n",
       " 'fastify / fastify',\n",
       " 'android / nowinandroid',\n",
       " 'grafana / loki',\n",
       " 'ory / kratos']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping Repository Title data\n",
    "title = driver.find_elements_by_xpath(\"//h1[@class = 'h3 lh-condensed']\")\n",
    "for i in title:\n",
    "    repository_title.append(i.text)\n",
    "repository_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c3fd3672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping data from all repository page\n",
    "for i in URLs:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    \n",
    "        # Scraping Repository Description data\n",
    "    try:\n",
    "        desc = driver.find_element_by_xpath(\"//p[@class='f4 mt-3']\")\n",
    "        Description.append(desc.text)\n",
    "    except NoSuchElementException:\n",
    "        Description.append('-')\n",
    "        \n",
    "        \n",
    "    # Scraping Contributors Count data\n",
    "    try:\n",
    "        contributor = driver.find_element_by_xpath(\"//*[contains(text(),'    Contributors ')]\")\n",
    "        Contributors.append(contributor.text.replace('Contributors',''))\n",
    "    except NoSuchElementException:\n",
    "        Contributors.append('-')\n",
    "        \n",
    "        \n",
    "    # Scraping Languages used data\n",
    "    try:\n",
    "        for i in driver.find_elements_by_xpath(\"//span[@class='color-text-primary text-bold mr-1']\"):\n",
    "            lang.append(i.text)\n",
    "        Language.append(lang)\n",
    "    except NoSuchElementException:\n",
    "        Language.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0740fa39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository title</th>\n",
       "      <th>Repository description</th>\n",
       "      <th>Contributors count</th>\n",
       "      <th>Language used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>atom / atom</td>\n",
       "      <td>-</td>\n",
       "      <td>489</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>saharmor / dalle-playground</td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>borisdayma / dalle-mini</td>\n",
       "      <td>-</td>\n",
       "      <td>17</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>openai / DALL-E</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>microsoft / Data-Science-For-Beginners</td>\n",
       "      <td>-</td>\n",
       "      <td>89</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>microsoft / ML-For-Beginners</td>\n",
       "      <td>-</td>\n",
       "      <td>115</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>papers-we-love / papers-we-love</td>\n",
       "      <td>-</td>\n",
       "      <td>255</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vaxerski / Hyprland</td>\n",
       "      <td>-</td>\n",
       "      <td>14</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NVlabs / eg3d</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>microsoft / Web-Dev-For-Beginners</td>\n",
       "      <td>-</td>\n",
       "      <td>136</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PaperMC / Paper</td>\n",
       "      <td>-</td>\n",
       "      <td>291</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>lapce / lapce</td>\n",
       "      <td>-</td>\n",
       "      <td>40</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RasaHQ / rasa</td>\n",
       "      <td>-</td>\n",
       "      <td>461</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CyC2018 / CS-Notes</td>\n",
       "      <td>-</td>\n",
       "      <td>231</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tvbb / z</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ahmedtariq01 / Cloud-DevOps-Learning-Resources</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>digitalocean / nginxconfig.io</td>\n",
       "      <td>-</td>\n",
       "      <td>41</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>jina-ai / dalle-flow</td>\n",
       "      <td>-</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>deepkit / deepkit-framework</td>\n",
       "      <td>-</td>\n",
       "      <td>14</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>shimohq / chinese-programmer-wrong-pronunciation</td>\n",
       "      <td>-</td>\n",
       "      <td>78</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>facebook / folly</td>\n",
       "      <td>-</td>\n",
       "      <td>665</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>fastify / fastify</td>\n",
       "      <td>-</td>\n",
       "      <td>506</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>android / nowinandroid</td>\n",
       "      <td>-</td>\n",
       "      <td>28</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>grafana / loki</td>\n",
       "      <td>-</td>\n",
       "      <td>539</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ory / kratos</td>\n",
       "      <td>-</td>\n",
       "      <td>171</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Repository title Repository description  \\\n",
       "0                                        atom / atom                      -   \n",
       "1                        saharmor / dalle-playground                      -   \n",
       "2                            borisdayma / dalle-mini                      -   \n",
       "3                                    openai / DALL-E                      -   \n",
       "4             microsoft / Data-Science-For-Beginners                      -   \n",
       "5                       microsoft / ML-For-Beginners                      -   \n",
       "6                    papers-we-love / papers-we-love                      -   \n",
       "7                                vaxerski / Hyprland                      -   \n",
       "8                                      NVlabs / eg3d                      -   \n",
       "9                  microsoft / Web-Dev-For-Beginners                      -   \n",
       "10                                   PaperMC / Paper                      -   \n",
       "11                                     lapce / lapce                      -   \n",
       "12                                     RasaHQ / rasa                      -   \n",
       "13                                CyC2018 / CS-Notes                      -   \n",
       "14                                          tvbb / z                      -   \n",
       "15    ahmedtariq01 / Cloud-DevOps-Learning-Resources                      -   \n",
       "16                     digitalocean / nginxconfig.io                      -   \n",
       "17                              jina-ai / dalle-flow                      -   \n",
       "18                       deepkit / deepkit-framework                      -   \n",
       "19  shimohq / chinese-programmer-wrong-pronunciation                      -   \n",
       "20                                  facebook / folly                      -   \n",
       "21                                 fastify / fastify                      -   \n",
       "22                            android / nowinandroid                      -   \n",
       "23                                    grafana / loki                      -   \n",
       "24                                      ory / kratos                      -   \n",
       "\n",
       "   Contributors count Language used  \n",
       "0                 489            []  \n",
       "1                   3            []  \n",
       "2                  17            []  \n",
       "3                   -            []  \n",
       "4                  89            []  \n",
       "5                 115            []  \n",
       "6                 255            []  \n",
       "7                  14            []  \n",
       "8                   2            []  \n",
       "9                 136            []  \n",
       "10                291            []  \n",
       "11                 40            []  \n",
       "12                461            []  \n",
       "13                231            []  \n",
       "14                  -            []  \n",
       "15                  -            []  \n",
       "16                 41            []  \n",
       "17                  4            []  \n",
       "18                 14            []  \n",
       "19                 78            []  \n",
       "20                665            []  \n",
       "21                506            []  \n",
       "22                 28            []  \n",
       "23                539            []  \n",
       "24                171            []  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame from scraped data\n",
    "Github=pd.DataFrame({})\n",
    "Github['Repository title'] = repository_title\n",
    "Github['Repository description'] = Description\n",
    "Github['Contributors count'] = Contributors\n",
    "Github['Language used'] = Language\n",
    "Github"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e59d9ab",
   "metadata": {},
   "source": [
    "Q6. Scrape the details of top 100 songs on billiboard.com.\n",
    "\n",
    "Url = https:/www.billboard.com/\n",
    "    \n",
    "You have to find the following details:\n",
    "    \n",
    "A) Song name\n",
    "\n",
    "B) Artist name\n",
    "\n",
    "C) Last week rank\n",
    "\n",
    "D) Peak rank\n",
    "\n",
    "E) Weeks on board\n",
    "\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ea5e409d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the webpage of mentioned url \n",
    "url=('https://www.billboard.com/')\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1668a000",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on 'hot' button\n",
    "hot = driver.find_element_by_xpath('//div[@class=\"lrv-u-flex lrv-u-background-color-white u-height-45\"]//li[1]')\n",
    "hot.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8e1929a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "songs = []       #Giving the empty list for all the coloumns, what all I want to extract.\n",
    "artists = []\n",
    "last = []\n",
    "peak = []\n",
    "board = []\n",
    "\n",
    "song = driver.find_elements_by_xpath('//li[@class=\"lrv-u-width-100p\"]//h3')    #Giving the xpath for all the columns, what all I want to extract.\n",
    "art = driver.find_elements_by_xpath('//li[@class=\"lrv-u-width-100p\"]/ul/li[1]//span[1]')\n",
    "las = driver.find_elements_by_xpath('//li[@class=\"lrv-u-width-100p\"]/ul/li[4]')\n",
    "pea = driver.find_elements_by_xpath('//li[@class=\"lrv-u-width-100p\"]/ul/li[5]')\n",
    "boa = driver.find_elements_by_xpath('//li[@class=\"lrv-u-width-100p\"]/ul/li[6]')\n",
    "\n",
    "for i in song:\n",
    "    songs.append(i.text)\n",
    "for j in art:\n",
    "    artists.append(j.text)\n",
    "for k in las:\n",
    "    last.append(k.text)\n",
    "for l in pea:\n",
    "    peak.append(l.text)\n",
    "for m in boa:\n",
    "    board.append(m.text)\n",
    "\n",
    "print(len(songs))       #Printing the length for all the columns.\n",
    "print(len(artists))\n",
    "print(len(last))\n",
    "print(len(peak))\n",
    "print(len(board))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "01da79cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Songs</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Last Week Rank</th>\n",
       "      <th>Peak rank</th>\n",
       "      <th>Weeks on board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As It Was</td>\n",
       "      <td>Harry Styles</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>First Class</td>\n",
       "      <td>Jack Harlow</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wait For U</td>\n",
       "      <td>Future Featuring Drake &amp; Tems</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>About Damn Time</td>\n",
       "      <td>Lizzo</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Heat Waves</td>\n",
       "      <td>Glass Animals</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Love You Better</td>\n",
       "      <td>Future</td>\n",
       "      <td>84</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Wild Hearts</td>\n",
       "      <td>Keith Urban</td>\n",
       "      <td>-</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Last Night Lonely</td>\n",
       "      <td>Jon Pardi</td>\n",
       "      <td>-</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>7500 OBO</td>\n",
       "      <td>Tim McGraw</td>\n",
       "      <td>-</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Until I Found You</td>\n",
       "      <td>Stephen Sanchez</td>\n",
       "      <td>-</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Songs                         Artist Last Week Rank Peak rank  \\\n",
       "0           As It Was                   Harry Styles              1         1   \n",
       "1         First Class                    Jack Harlow              2         1   \n",
       "2          Wait For U  Future Featuring Drake & Tems              3         1   \n",
       "3     About Damn Time                          Lizzo              5         4   \n",
       "4          Heat Waves                  Glass Animals              6         1   \n",
       "..                ...                            ...            ...       ...   \n",
       "95    Love You Better                         Future             84        12   \n",
       "96        Wild Hearts                    Keith Urban              -        97   \n",
       "97  Last Night Lonely                      Jon Pardi              -        98   \n",
       "98           7500 OBO                     Tim McGraw              -        99   \n",
       "99  Until I Found You                Stephen Sanchez              -       100   \n",
       "\n",
       "   Weeks on board  \n",
       "0               9  \n",
       "1               8  \n",
       "2               5  \n",
       "3               7  \n",
       "4              72  \n",
       "..            ...  \n",
       "95              5  \n",
       "96              1  \n",
       "97              1  \n",
       "98              1  \n",
       "99              1  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame from scraped data\n",
    "df = pd.DataFrame({'Songs':songs,\n",
    "                   'Artist':artists,\n",
    "                   'Last Week Rank':last,\n",
    "                   'Peak rank':peak,\n",
    "                   'Weeks on board':board})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a37f6aa",
   "metadata": {},
   "source": [
    "Q7: Scrape the details of Data science recruiters from naukri.com.\n",
    "\n",
    "Url = https://www.naukri.com/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Name\n",
    "\n",
    "B) Designation\n",
    "\n",
    "C) Company\n",
    "\n",
    "D) Skills they hire for\n",
    "\n",
    "E) Location\n",
    "\n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and click on search. All this should be done through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6552d00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Surjit Singh Kadian\\Downloads\\chromedriver_win32 (1)\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "93ce4734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the webpage of mentioned url \n",
    "url6 = 'https://www.naukri.com/data-collection-recruiters'  #Giving the url\n",
    "driver.get(url6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0d6378d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "63eec472",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element_by_xpath('//*[@id=\"skill\"]/div[1]/div[2]/input') #Giving the xpath for the search button\n",
    "search.clear()\n",
    "search.send_keys('Data Scientist')              #sending the data to be typed in the search box.\n",
    "time.sleep(2)\n",
    "searchh = driver.find_element_by_xpath('//*[@id=\"qsbFormBtn\"]')   #Clicking on the 'Search' button.\n",
    "searchh.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "cfe32e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n",
      "50\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "name = []           #Giving the empty list\n",
    "designation = [] \n",
    "company = []\n",
    "skills = []\n",
    "\n",
    "nam = driver.find_elements_by_xpath('//div[@class=\"recInfo\"]/div[1]/p/a/span')     #Giving the Xpath for all the columns\n",
    "desi = driver.find_elements_by_xpath('//div[@class=\"recInfo\"]/div[1]/p/span[1]')\n",
    "comp = driver.find_elements_by_xpath('//div[@class=\"recInfo\"]/div[1]/p/a[2]')\n",
    "skill = driver.find_elements_by_xpath('//div[@class=\"recInfo\"]/div[2]')\n",
    "\n",
    "for i in nam:                  \n",
    "    name.append(i.text)                                 #Iterating the text data\n",
    "for j in desi:\n",
    "    designation.append(j.text)\n",
    "for k in comp:\n",
    "    company.append(k.text)\n",
    "for n in skill:\n",
    "    skills.append(n.text)\n",
    "\n",
    "print(len(name))                                #Printing the length of the data\n",
    "print(len(designation))\n",
    "print(len(company))\n",
    "print(len(skills))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "fe4be320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "# Used the concept of BeautifulSoup, So that I can use try and except method, As in selenium try and except was not working properly. \n",
    "location=[]            \n",
    "soup=BeautifulSoup(driver.page_source,'html.parser')      #Gave the page source\n",
    "l=soup.find_all('div',attrs={'vcard'})                    #Gave the class name and the attribute name\n",
    "for i in l:\n",
    "    try:                                         #Used Try and except method\n",
    "        location.append(i.find('small').text)              #Appending the text data\n",
    "    except AttributeError :\n",
    "        location.append(\"No details available\")\n",
    "print(len(location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d0bc7196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Company</th>\n",
       "      <th>Skills Needed</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanushree</td>\n",
       "      <td>Lead Recruiter</td>\n",
       "      <td>RecRoots</td>\n",
       "      <td>UI Developers, Software Engineers, Quality Ass...</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sashi bhushan</td>\n",
       "      <td>Senior Specialist</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>pig, hbase, sas, spss, apache, python, nosql, ...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bitapi</td>\n",
       "      <td>HR and Operation Manager</td>\n",
       "      <td>Anvaya</td>\n",
       "      <td>Hadoop, Big Data, Data Scientists, Java, Sprin...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gajendra Singh</td>\n",
       "      <td>Head of Recruitment - Product &amp;amp;...</td>\n",
       "      <td>A Leading of Product Start-UP Company</td>\n",
       "      <td>Data Scientist, Big Data, Hadoop, Web Analytic...</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sadashiv Kulkarni</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>Digitially Insights Pvt Ltd</td>\n",
       "      <td>Big Data Engineer, Data Scientist, Solutions, ...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Invelopment</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>Invelopment</td>\n",
       "      <td>Scandinavian Startups</td>\n",
       "      <td>Ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Anjali Srivastava</td>\n",
       "      <td>Director HR</td>\n",
       "      <td>CodeFire Technologies Pvt. Ltd.</td>\n",
       "      <td>Technical, Business Development Executive, Sof...</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Helly Vyas</td>\n",
       "      <td>HR Business Partner</td>\n",
       "      <td>AM - TA &amp;amp; HR</td>\n",
       "      <td>Big Data technology, PLSQL, Web Developer, Jav...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ashish Verma</td>\n",
       "      <td>Senior Associate Human Resources</td>\n",
       "      <td>Evalueserve.com Private Limited</td>\n",
       "      <td>SAS, VBA, Business Information Services(BIS), ...</td>\n",
       "      <td>Gurgaon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Balaji Prabhakaran</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Oportun</td>\n",
       "      <td>Technical Solution Architect, Data Scientist, ...</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shiva Kumar N</td>\n",
       "      <td>Founder</td>\n",
       "      <td>Rapid Talent Solutions -9148242334</td>\n",
       "      <td>salaesforce, Web Technologies, .net, .net full...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bhuwneshari Devi</td>\n",
       "      <td>Lead Talent Acquisition</td>\n",
       "      <td>Success Pact Consulting</td>\n",
       "      <td>Amazon, Olacabs, Quikr, Bankbazzar, Uber, Flip...</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HS Sandesh</td>\n",
       "      <td>Talent Evangelist www staffiohr co</td>\n",
       "      <td>Staffio HR</td>\n",
       "      <td>Digital Marketing, General Manager, Business D...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Anoop Somarajan</td>\n",
       "      <td>Manager - Talent Acquisition</td>\n",
       "      <td>R1RCM</td>\n",
       "      <td>Asp.net, Hl7, Mirth, Perl, Xamarin, Javascript...</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Datafoundry</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>JAITRA SOFTWARE SOLUTIONS PVT LTD</td>\n",
       "      <td>Webmethods Developer, Mean Stack, Business Ana...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A Valsa Florina</td>\n",
       "      <td>Recruitment Specialist</td>\n",
       "      <td>Redbus.in</td>\n",
       "      <td>Business Analyst, Front end developer, legal, ...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kalaivani M V</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>ZYUDLY LABS DATA SOLUTIONS PRIVATE LIMITED</td>\n",
       "      <td>Data Scientist, Cloud Computing, Mobile Applic...</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Prashant K</td>\n",
       "      <td>Sr HR</td>\n",
       "      <td>Confidential</td>\n",
       "      <td>Data Analyst, Statistical Analysis, Data Scien...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Radhika</td>\n",
       "      <td>HR Associate</td>\n",
       "      <td>Bright Bridge Info-tech Pvt Ltd</td>\n",
       "      <td>business analyst - IT (python), pay per click,...</td>\n",
       "      <td>Coimbatore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Rakhi</td>\n",
       "      <td>HR recruiter</td>\n",
       "      <td>Constalytics</td>\n",
       "      <td>Data Scientist, Data Research Analyst, Big Dat...</td>\n",
       "      <td>Singapore - (singapore)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Monika Jain</td>\n",
       "      <td>Talent Aquistion Lead</td>\n",
       "      <td>Info Edge India Limited</td>\n",
       "      <td>Lamp Developer, Ui/ux Developer, Qa Engineer, ...</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Trilok Nath</td>\n",
       "      <td>Senior IT Recruiter</td>\n",
       "      <td>Molveno Consulting Private Limited</td>\n",
       "      <td>.Net Developers With Angular Js, Html, Front E...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Rashmi Kathuria</td>\n",
       "      <td>Talent Acquisition Specialist (Specialized...</td>\n",
       "      <td>Mount Talent consulting</td>\n",
       "      <td>Leading MNCs, Product based organizations</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Vidya Rani Hadimani</td>\n",
       "      <td>Business Manager Delivery</td>\n",
       "      <td>Talent Management Labs Inc.</td>\n",
       "      <td>Amazon Walmart Adobe OLA Myntracom Komli Media...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Monika Singh Thakur</td>\n",
       "      <td>Technical Recruiter</td>\n",
       "      <td>ValueLabs</td>\n",
       "      <td>Big Data Analytics, Marketing Analytics, Full ...</td>\n",
       "      <td>Indore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Shikha Bakshi</td>\n",
       "      <td>Senior Manager Recruitment</td>\n",
       "      <td>Fractal Analytics!!</td>\n",
       "      <td>Analytics, Big Data, Hadoop, Python</td>\n",
       "      <td>Gurgaon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Abhishek - Only Analytics Hiring - India and</td>\n",
       "      <td>Recruitment Lead Consultant</td>\n",
       "      <td>Apidel Technologies Division of Transpower</td>\n",
       "      <td>Analytics, Business Intelligence, Business Ana...</td>\n",
       "      <td>Vadodara / Baroda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Jayanth N</td>\n",
       "      <td>Project Manager</td>\n",
       "      <td>Dollarbird Information Services Pvt, Ltd</td>\n",
       "      <td>Data Analytics, Managed Services, Team Leading...</td>\n",
       "      <td>Mysoru / Mysore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Sai Siddharth Chinta</td>\n",
       "      <td>Technical Recruiter</td>\n",
       "      <td>McKinsey &amp;amp; Company</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Ravi</td>\n",
       "      <td>Team HR</td>\n",
       "      <td>Einfluss Teknocommercial Pvt. Ltd.</td>\n",
       "      <td>Deep Learning, Machine Learning, unstructured ...</td>\n",
       "      <td>Ghaziabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Ishu Kumar</td>\n",
       "      <td>Co Founder &amp;amp; Ceo</td>\n",
       "      <td>Data X</td>\n",
       "      <td>Python, Machine Learning, Sql, Data Science</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Vivek Shrivastava</td>\n",
       "      <td>Assistant Manager Human Resources</td>\n",
       "      <td>InnovAccer Management Pvt Ltd</td>\n",
       "      <td>Business Analyst, analytics, Decesion Scientis...</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Gayathri E</td>\n",
       "      <td>Sr Recruitment</td>\n",
       "      <td>Wonderwrks IT Services Private Limited</td>\n",
       "      <td>IT Infrastructure Management, PHP, Wordpress, ...</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Best In Town Analytics</td>\n",
       "      <td>Analytics Associate</td>\n",
       "      <td>BITA</td>\n",
       "      <td>Data Analytics</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Santhosh Nagaiah</td>\n",
       "      <td>Chief marketing officer</td>\n",
       "      <td>Tuple Technologies Pte Ltd</td>\n",
       "      <td>Data Science, Project Management, Backend</td>\n",
       "      <td>No details available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>priyanka</td>\n",
       "      <td>General Manager</td>\n",
       "      <td>Reliance Industries</td>\n",
       "      <td>Sap, Saas, Sql, Hadoop, Production Planning, B...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Nagendla Syam Kumar</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>FLOWERHORN IT PVT LTD</td>\n",
       "      <td>Machine Learning, NLP, Performance Review, HR,...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Renny Benita K</td>\n",
       "      <td>Operations Manager</td>\n",
       "      <td>DeepIQ Software Solutions Pvt Ltd</td>\n",
       "      <td>Core Java, J2ee, Big Data, Machine Learning, D...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Jamil Akhtar</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Quikkloan</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Roshan Menugu</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Cyient Limited</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Sudipta Samanta</td>\n",
       "      <td>Founder</td>\n",
       "      <td>DataNnoviteSol LLP</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>HR Team</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>Terra Blue Exploration Technologies Pvt....</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>rajesh</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td>quantum value IT services</td>\n",
       "      <td>Data Scientist, Tableau, R Tool, Data Analytic...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>navya neluri</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>asens labs</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Ram Kumar</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Working As A Freelancer</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Laksh Barla</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td>SYSVINE TECHNOLOGIES PRIVATE LIMITED</td>\n",
       "      <td>Devops, Ruby Rails, Java, Spring, Net, Angular...</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Zack</td>\n",
       "      <td>Recruitment Manager</td>\n",
       "      <td>Perex Engineering Pvt Ltd</td>\n",
       "      <td>Software Development, Javascript, Core Java, J...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Shreya Naithani</td>\n",
       "      <td>Talent Acquisition Executive</td>\n",
       "      <td>Purplejack Labs Pvt. Ltd.</td>\n",
       "      <td>Node.js, React.js, Etl Testing, Data Warehousi...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Vanitha Senkurichi</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>Quaero 3 India Ltd</td>\n",
       "      <td>sql, Ui Development, ssis, Data Modeling, Data...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Sravan Kumar Ranga</td>\n",
       "      <td>Assistant Manager</td>\n",
       "      <td>GSPANN Technologies</td>\n",
       "      <td>devops, build and release, Delivery Manager, O...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Name  \\\n",
       "0                                      Tanushree   \n",
       "1                                  sashi bhushan   \n",
       "2                                         Bitapi   \n",
       "3                                 Gajendra Singh   \n",
       "4                              Sadashiv Kulkarni   \n",
       "5                                    Invelopment   \n",
       "6                              Anjali Srivastava   \n",
       "7                                     Helly Vyas   \n",
       "8                                   Ashish Verma   \n",
       "9                             Balaji Prabhakaran   \n",
       "10                                 Shiva Kumar N   \n",
       "11                              Bhuwneshari Devi   \n",
       "12                                    HS Sandesh   \n",
       "13                               Anoop Somarajan   \n",
       "14                                   Datafoundry   \n",
       "15                               A Valsa Florina   \n",
       "16                                 Kalaivani M V   \n",
       "17                                    Prashant K   \n",
       "18                                       Radhika   \n",
       "19                                         Rakhi   \n",
       "20                                   Monika Jain   \n",
       "21                                   Trilok Nath   \n",
       "22                               Rashmi Kathuria   \n",
       "23                           Vidya Rani Hadimani   \n",
       "24                           Monika Singh Thakur   \n",
       "25                                 Shikha Bakshi   \n",
       "26  Abhishek - Only Analytics Hiring - India and   \n",
       "27                                     Jayanth N   \n",
       "28                          Sai Siddharth Chinta   \n",
       "29                                          Ravi   \n",
       "30                                    Ishu Kumar   \n",
       "31                             Vivek Shrivastava   \n",
       "32                                    Gayathri E   \n",
       "33                        Best In Town Analytics   \n",
       "34                              Santhosh Nagaiah   \n",
       "35                                      priyanka   \n",
       "36                           Nagendla Syam Kumar   \n",
       "37                                Renny Benita K   \n",
       "38                                  Jamil Akhtar   \n",
       "39                                 Roshan Menugu   \n",
       "40                               Sudipta Samanta   \n",
       "41                                       HR Team   \n",
       "42                                        rajesh   \n",
       "43                                  navya neluri   \n",
       "44                                     Ram Kumar   \n",
       "45                                   Laksh Barla   \n",
       "46                                          Zack   \n",
       "47                               Shreya Naithani   \n",
       "48                            Vanitha Senkurichi   \n",
       "49                            Sravan Kumar Ranga   \n",
       "\n",
       "                                      Designation  \\\n",
       "0                                  Lead Recruiter   \n",
       "1                               Senior Specialist   \n",
       "2                        HR and Operation Manager   \n",
       "3          Head of Recruitment - Product &amp;...   \n",
       "4                                      Company HR   \n",
       "5                                      Company HR   \n",
       "6                                     Director HR   \n",
       "7                             HR Business Partner   \n",
       "8                Senior Associate Human Resources   \n",
       "9                               Company Recruiter   \n",
       "10                                        Founder   \n",
       "11                        Lead Talent Acquisition   \n",
       "12             Talent Evangelist www staffiohr co   \n",
       "13                   Manager - Talent Acquisition   \n",
       "14                                     Company HR   \n",
       "15                         Recruitment Specialist   \n",
       "16                                     HR Manager   \n",
       "17                                          Sr HR   \n",
       "18                                   HR Associate   \n",
       "19                                   HR recruiter   \n",
       "20                          Talent Aquistion Lead   \n",
       "21                            Senior IT Recruiter   \n",
       "22  Talent Acquisition Specialist (Specialized...   \n",
       "23                      Business Manager Delivery   \n",
       "24                            Technical Recruiter   \n",
       "25                     Senior Manager Recruitment   \n",
       "26                    Recruitment Lead Consultant   \n",
       "27                                Project Manager   \n",
       "28                            Technical Recruiter   \n",
       "29                                        Team HR   \n",
       "30                           Co Founder &amp; Ceo   \n",
       "31              Assistant Manager Human Resources   \n",
       "32                                 Sr Recruitment   \n",
       "33                            Analytics Associate   \n",
       "34                        Chief marketing officer   \n",
       "35                                General Manager   \n",
       "36                                 Data Scientist   \n",
       "37                             Operations Manager   \n",
       "38                              Company Recruiter   \n",
       "39                              Company Recruiter   \n",
       "40                                        Founder   \n",
       "41                                     Company HR   \n",
       "42                                   HR Executive   \n",
       "43                                 Data Scientist   \n",
       "44                                 Data Scientist   \n",
       "45                                   HR Executive   \n",
       "46                            Recruitment Manager   \n",
       "47                   Talent Acquisition Executive   \n",
       "48                                     Company HR   \n",
       "49                              Assistant Manager   \n",
       "\n",
       "                                        Company  \\\n",
       "0                                      RecRoots   \n",
       "1                                         Wipro   \n",
       "2                                        Anvaya   \n",
       "3         A Leading of Product Start-UP Company   \n",
       "4                   Digitially Insights Pvt Ltd   \n",
       "5                                   Invelopment   \n",
       "6               CodeFire Technologies Pvt. Ltd.   \n",
       "7                              AM - TA &amp; HR   \n",
       "8               Evalueserve.com Private Limited   \n",
       "9                                       Oportun   \n",
       "10           Rapid Talent Solutions -9148242334   \n",
       "11                      Success Pact Consulting   \n",
       "12                                   Staffio HR   \n",
       "13                                        R1RCM   \n",
       "14            JAITRA SOFTWARE SOLUTIONS PVT LTD   \n",
       "15                                    Redbus.in   \n",
       "16   ZYUDLY LABS DATA SOLUTIONS PRIVATE LIMITED   \n",
       "17                                 Confidential   \n",
       "18              Bright Bridge Info-tech Pvt Ltd   \n",
       "19                                 Constalytics   \n",
       "20                      Info Edge India Limited   \n",
       "21           Molveno Consulting Private Limited   \n",
       "22                      Mount Talent consulting   \n",
       "23                  Talent Management Labs Inc.   \n",
       "24                                    ValueLabs   \n",
       "25                          Fractal Analytics!!   \n",
       "26   Apidel Technologies Division of Transpower   \n",
       "27     Dollarbird Information Services Pvt, Ltd   \n",
       "28                       McKinsey &amp; Company   \n",
       "29           Einfluss Teknocommercial Pvt. Ltd.   \n",
       "30                                       Data X   \n",
       "31                InnovAccer Management Pvt Ltd   \n",
       "32       Wonderwrks IT Services Private Limited   \n",
       "33                                         BITA   \n",
       "34                   Tuple Technologies Pte Ltd   \n",
       "35                          Reliance Industries   \n",
       "36                        FLOWERHORN IT PVT LTD   \n",
       "37            DeepIQ Software Solutions Pvt Ltd   \n",
       "38                                    Quikkloan   \n",
       "39                               Cyient Limited   \n",
       "40                           DataNnoviteSol LLP   \n",
       "41  Terra Blue Exploration Technologies Pvt....   \n",
       "42                    quantum value IT services   \n",
       "43                                   asens labs   \n",
       "44                      Working As A Freelancer   \n",
       "45         SYSVINE TECHNOLOGIES PRIVATE LIMITED   \n",
       "46                    Perex Engineering Pvt Ltd   \n",
       "47                    Purplejack Labs Pvt. Ltd.   \n",
       "48                           Quaero 3 India Ltd   \n",
       "49                          GSPANN Technologies   \n",
       "\n",
       "                                        Skills Needed  \\\n",
       "0   UI Developers, Software Engineers, Quality Ass...   \n",
       "1   pig, hbase, sas, spss, apache, python, nosql, ...   \n",
       "2   Hadoop, Big Data, Data Scientists, Java, Sprin...   \n",
       "3   Data Scientist, Big Data, Hadoop, Web Analytic...   \n",
       "4   Big Data Engineer, Data Scientist, Solutions, ...   \n",
       "5                               Scandinavian Startups   \n",
       "6   Technical, Business Development Executive, Sof...   \n",
       "7   Big Data technology, PLSQL, Web Developer, Jav...   \n",
       "8   SAS, VBA, Business Information Services(BIS), ...   \n",
       "9   Technical Solution Architect, Data Scientist, ...   \n",
       "10  salaesforce, Web Technologies, .net, .net full...   \n",
       "11  Amazon, Olacabs, Quikr, Bankbazzar, Uber, Flip...   \n",
       "12  Digital Marketing, General Manager, Business D...   \n",
       "13  Asp.net, Hl7, Mirth, Perl, Xamarin, Javascript...   \n",
       "14  Webmethods Developer, Mean Stack, Business Ana...   \n",
       "15  Business Analyst, Front end developer, legal, ...   \n",
       "16  Data Scientist, Cloud Computing, Mobile Applic...   \n",
       "17  Data Analyst, Statistical Analysis, Data Scien...   \n",
       "18  business analyst - IT (python), pay per click,...   \n",
       "19  Data Scientist, Data Research Analyst, Big Dat...   \n",
       "20  Lamp Developer, Ui/ux Developer, Qa Engineer, ...   \n",
       "21  .Net Developers With Angular Js, Html, Front E...   \n",
       "22          Leading MNCs, Product based organizations   \n",
       "23  Amazon Walmart Adobe OLA Myntracom Komli Media...   \n",
       "24  Big Data Analytics, Marketing Analytics, Full ...   \n",
       "25                Analytics, Big Data, Hadoop, Python   \n",
       "26  Analytics, Business Intelligence, Business Ana...   \n",
       "27  Data Analytics, Managed Services, Team Leading...   \n",
       "28                                      Not Specified   \n",
       "29  Deep Learning, Machine Learning, unstructured ...   \n",
       "30        Python, Machine Learning, Sql, Data Science   \n",
       "31  Business Analyst, analytics, Decesion Scientis...   \n",
       "32  IT Infrastructure Management, PHP, Wordpress, ...   \n",
       "33                                     Data Analytics   \n",
       "34          Data Science, Project Management, Backend   \n",
       "35  Sap, Saas, Sql, Hadoop, Production Planning, B...   \n",
       "36  Machine Learning, NLP, Performance Review, HR,...   \n",
       "37  Core Java, J2ee, Big Data, Machine Learning, D...   \n",
       "38                                      Not Specified   \n",
       "39                                      Not Specified   \n",
       "40                                      Not Specified   \n",
       "41                                      Not Specified   \n",
       "42  Data Scientist, Tableau, R Tool, Data Analytic...   \n",
       "43                                      Not Specified   \n",
       "44                                      Not Specified   \n",
       "45  Devops, Ruby Rails, Java, Spring, Net, Angular...   \n",
       "46  Software Development, Javascript, Core Java, J...   \n",
       "47  Node.js, React.js, Etl Testing, Data Warehousi...   \n",
       "48  sql, Ui Development, ssis, Data Modeling, Data...   \n",
       "49  devops, build and release, Delivery Manager, O...   \n",
       "\n",
       "                    Location  \n",
       "0                      Noida  \n",
       "1      Bengaluru / Bangalore  \n",
       "2      Bengaluru / Bangalore  \n",
       "3                      Noida  \n",
       "4                       Pune  \n",
       "5                  Ahmedabad  \n",
       "6                      Noida  \n",
       "7                       Pune  \n",
       "8                    Gurgaon  \n",
       "9                    Chennai  \n",
       "10     Bengaluru / Bangalore  \n",
       "11                     Delhi  \n",
       "12     Bengaluru / Bangalore  \n",
       "13                   Chennai  \n",
       "14     Bengaluru / Bangalore  \n",
       "15     Bengaluru / Bangalore  \n",
       "16                   Chennai  \n",
       "17     Bengaluru / Bangalore  \n",
       "18                Coimbatore  \n",
       "19   Singapore - (singapore)  \n",
       "20                     Noida  \n",
       "21  Hyderabad / Secunderabad  \n",
       "22                     Noida  \n",
       "23     Bengaluru / Bangalore  \n",
       "24                    Indore  \n",
       "25                   Gurgaon  \n",
       "26         Vadodara / Baroda  \n",
       "27           Mysoru / Mysore  \n",
       "28     Bengaluru / Bangalore  \n",
       "29                 Ghaziabad  \n",
       "30     Bengaluru / Bangalore  \n",
       "31                     Noida  \n",
       "32                   Chennai  \n",
       "33     Bengaluru / Bangalore  \n",
       "34      No details available  \n",
       "35                    Mumbai  \n",
       "36     Bengaluru / Bangalore  \n",
       "37     Bengaluru / Bangalore  \n",
       "38                     Delhi  \n",
       "39  Hyderabad / Secunderabad  \n",
       "40                      Pune  \n",
       "41     Bengaluru / Bangalore  \n",
       "42     Bengaluru / Bangalore  \n",
       "43  Hyderabad / Secunderabad  \n",
       "44                      Pune  \n",
       "45                   Chennai  \n",
       "46  Hyderabad / Secunderabad  \n",
       "47                    Mumbai  \n",
       "48     Bengaluru / Bangalore  \n",
       "49  Hyderabad / Secunderabad  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame from scraped data\n",
    "df = pd.DataFrame({'Name':name,\n",
    "                   'Designation':designation,\n",
    "                   'Company':company,\n",
    "                   'Skills Needed':skills,\n",
    "                   'Location':location})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc361959",
   "metadata": {},
   "source": [
    "Q8. Scrape the details of Highest selling novels.\n",
    "\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-greycompare/\n",
    "    \n",
    "You have to find the following details:\n",
    "    \n",
    "A) Book name\n",
    "\n",
    "B) Author name\n",
    "\n",
    "C) Volumes sold\n",
    "\n",
    "D) Publisher\n",
    "\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "77ff307d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the webpage of mentioned url \n",
    "url = 'https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare'  \n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "cbbec1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "title = []           #Giving the empty list for all the coloumns, what all I want to extract.\n",
    "author = []\n",
    "volume = []\n",
    "publisher = []\n",
    "genre = []\n",
    "\n",
    "tit = driver.find_elements_by_xpath('//table[@class=\"in-article sortable\"]//tbody//tr//td[2]')     #Giving the xpath\n",
    "aut = driver.find_elements_by_xpath('//table[@class=\"in-article sortable\"]//tbody//tr//td[3]')\n",
    "vol = driver.find_elements_by_xpath('//table[@class=\"in-article sortable\"]//tbody//tr//td[4]')\n",
    "pub = driver.find_elements_by_xpath('//table[@class=\"in-article sortable\"]//tbody//tr//td[5]')\n",
    "gen = driver.find_elements_by_xpath('//table[@class=\"in-article sortable\"]//tbody//tr//td[6]')\n",
    "\n",
    "for i in tit:\n",
    "    title.append(i.text)                                           #Appending the text data\n",
    "for j in aut:\n",
    "    author.append(j.text)\n",
    "for k in vol:\n",
    "    volume.append(k.text)\n",
    "for l in pub:\n",
    "    publisher.append(l.text)\n",
    "for m in gen:\n",
    "    genre.append(m.text)\n",
    "    \n",
    "print(len(title))                                          #Printing the length of all the columns.\n",
    "print(len(author))\n",
    "print(len(volume))\n",
    "print(len(publisher))\n",
    "print(len(genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "eff19481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book name</th>\n",
       "      <th>Author name</th>\n",
       "      <th>Volumes sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book name       Author name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame from scraped data\n",
    "df = pd.DataFrame({'Book name':title,\n",
    "                   'Author name':author,\n",
    "                   'Volumes sold':volume,\n",
    "                   'Publisher':publisher,\n",
    "                   'Genre':genre})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e7aa9b",
   "metadata": {},
   "source": [
    "Q9. Scrape the details most watched tv series of all time from imdb.com.\n",
    "\n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "    \n",
    "You have to find the following details:\n",
    "    \n",
    "A) Name\n",
    "\n",
    "B) Year span\n",
    "\n",
    "C) Genre\n",
    "\n",
    "D) Run time\n",
    "\n",
    "E) Ratings\n",
    "\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "20dc53a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the webpage of mentioned url \n",
    "url = 'https://www.imdb.com/list/ls095964455'    \n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ccb9ec10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "name = []                             #Giving the empty list for all the columns, what all I want to extract\n",
    "year = []\n",
    "genre = []\n",
    "time = []\n",
    "ratings = []\n",
    "votes = []\n",
    "\n",
    "nam = driver.find_elements_by_xpath('//div[@class=\"lister-item-content\"]/h3/a')            #Giving the Xpath\n",
    "yea = driver.find_elements_by_xpath('//div[@class=\"lister-item-content\"]/h3/span[2]')\n",
    "gen = driver.find_elements_by_xpath('//p[@class=\"text-muted text-small\"]//span[5]')\n",
    "tim = driver.find_elements_by_xpath('//p[@class=\"text-muted text-small\"]//span[3]')\n",
    "rat = driver.find_elements_by_xpath('//div[@class=\"ipl-rating-widget\"]/div/span[2]')\n",
    "vot = driver.find_elements_by_xpath('//p[@class=\"text-muted text-small\"][3]/span[2]')\n",
    "\n",
    "for i in nam:\n",
    "    name.append(i.text)                               #Iterating the text data from the data what I have extracted.\n",
    "for j in yea:\n",
    "    year.append(j.text)\n",
    "for k in gen:\n",
    "    genre.append(k.text)\n",
    "for l in tim:\n",
    "    time.append(l.text)\n",
    "for m in rat:\n",
    "    ratings.append(m.text)\n",
    "for n in vot:\n",
    "    votes.append(n.text)\n",
    "\n",
    "print(len(name))                                     #Printing the length of the data\n",
    "print(len(year))\n",
    "print(len(genre))\n",
    "print(len(time))\n",
    "print(len(ratings))\n",
    "print(len(votes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9800d225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1,994,668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,033,442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.2</td>\n",
       "      <td>949,447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>283,688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>243,474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama, Fantasy</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>48,856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>59,538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005–2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>190,386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>40,295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>228,737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name         Year                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things     (2016– )    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)            Drama, Fantasy   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds  (2005–2020)     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run Time Ratings      Votes  \n",
       "0    57 min     9.2  1,994,668  \n",
       "1    51 min     8.7  1,033,442  \n",
       "2    44 min     8.2    949,447  \n",
       "3    60 min     7.5    283,688  \n",
       "4    43 min     7.6    243,474  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.4     48,856  \n",
       "96   50 min     7.8     59,538  \n",
       "97   42 min     8.1    190,386  \n",
       "98   45 min     7.1     40,295  \n",
       "99  572 min     8.6    228,737  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame from scraped data\n",
    "df = pd.DataFrame({'Name':name,\n",
    "                   'Year':year,\n",
    "                   'Genre':genre,\n",
    "                   'Run Time':time,\n",
    "                   'Ratings':ratings,\n",
    "                   'Votes':votes})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25508254",
   "metadata": {},
   "source": [
    "Q10. Details of Datasets from UCI machine learning repositories.\n",
    "\n",
    "Url = https://archive.ics.uci.edu/\n",
    "    \n",
    "You have to find the following details:\n",
    "    \n",
    "A) Dataset name\n",
    "\n",
    "B) Data type\n",
    "\n",
    "C) Task\n",
    "\n",
    "D) Attribute type\n",
    "\n",
    "E) No of instances\n",
    "\n",
    "F) No of attribute\n",
    "\n",
    "G) Year\n",
    "\n",
    "Note: - from the home page you have to go to the ShowAllDataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "12b3a0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the webpage of mentioned url \n",
    "url = 'https://archive.ics.uci.edu/'     \n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2f323ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on 'View' button\n",
    "view = driver.find_element_by_xpath('//span[@class=\"whitetext\"][2]/a[1]')\n",
    "view.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "576eb5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622\n",
      "622\n",
      "622\n",
      "622\n",
      "622\n",
      "622\n",
      "622\n"
     ]
    }
   ],
   "source": [
    "name = []                 #Giving the empty list for all the columns, what all I want to extract.\n",
    "typee = []\n",
    "task = []\n",
    "attribute = []\n",
    "instances = []\n",
    "attributes = []\n",
    "year = []\n",
    "\n",
    "nam = driver.find_elements_by_xpath('//table[@cellpadding = \"3\"]/tbody/tr/td[2]/table[2]/tbody/tr/td[1]')     #Giving the Xpath\n",
    "typ = driver.find_elements_by_xpath('//table[@cellpadding = \"3\"]/tbody/tr/td[2]/table[2]/tbody/tr/td[2]')\n",
    "tas = driver.find_elements_by_xpath('//table[@cellpadding=\"3\"]/tbody/tr/td[2]/table[2]/tbody/tr/td[3]')\n",
    "attri = driver.find_elements_by_xpath('//table[@cellpadding=\"3\"]/tbody/tr/td[2]/table[2]/tbody/tr/td[4]')\n",
    "inst = driver.find_elements_by_xpath('//table[@cellpadding=\"3\"]/tbody/tr/td[2]/table[2]/tbody/tr/td[5]')\n",
    "attri = driver.find_elements_by_xpath('//table[@cellpadding=\"3\"]/tbody/tr/td[2]/table[2]/tbody/tr/td[6]')\n",
    "yea = driver.find_elements_by_xpath('//table[@cellpadding=\"3\"]/tbody/tr/td[2]/table[2]/tbody/tr/td[7]')\n",
    "\n",
    "for i in nam[1:]:                               #Used the concept of indexing to extract the desired data\n",
    "    name.append(i.text)                         #Appending the text data\n",
    "for j in typ[1:]:\n",
    "    typee.append(j.text)\n",
    "for k in tas[1:]:\n",
    "    task.append(k.text)\n",
    "for l in attri[1:]:\n",
    "    attribute.append(l.text)\n",
    "for m in inst[1:]:\n",
    "    instances.append(m.text)\n",
    "for n in attri[1:]:\n",
    "    attributes.append(n.text)\n",
    "for o in yea[1:]:\n",
    "    year.append(o.text)\n",
    "    \n",
    "print(len(name))                          #Printing the length for all the columns\n",
    "print(len(typee))\n",
    "print(len(task))\n",
    "print(len(attribute))\n",
    "print(len(instances))\n",
    "print(len(attributes))\n",
    "print(len(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d78e6d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Data Types</th>\n",
       "      <th>Default Task</th>\n",
       "      <th>Attribute Types</th>\n",
       "      <th>Number of Instances</th>\n",
       "      <th>Number of Attributes</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>8</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>14</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>38</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td></td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>294</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>279</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Influenza outbreak event prediction via Twit...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>525</td>\n",
       "      <td>75840</td>\n",
       "      <td>525</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Turkish Music Emotion Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>50</td>\n",
       "      <td>400</td>\n",
       "      <td>50</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Maternal Health Risk Data Set</td>\n",
       "      <td></td>\n",
       "      <td>Classification</td>\n",
       "      <td>7</td>\n",
       "      <td>1014</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Room Occupancy Estimation</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>16</td>\n",
       "      <td>10129</td>\n",
       "      <td>16</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Image Recognition Task Execution Times in Mo...</td>\n",
       "      <td>Univariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>2</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Name  \\\n",
       "0                                              Abalone   \n",
       "1                                                Adult   \n",
       "2                                            Annealing   \n",
       "3                         Anonymous Microsoft Web Data   \n",
       "4                                           Arrhythmia   \n",
       "..                                                 ...   \n",
       "617    Influenza outbreak event prediction via Twit...   \n",
       "618                      Turkish Music Emotion Dataset   \n",
       "619                      Maternal Health Risk Data Set   \n",
       "620                          Room Occupancy Estimation   \n",
       "621    Image Recognition Task Execution Times in Mo...   \n",
       "\n",
       "                     Data Types          Default Task Attribute Types  \\\n",
       "0                 Multivariate        Classification               8    \n",
       "1                 Multivariate        Classification              14    \n",
       "2                 Multivariate        Classification              38    \n",
       "3                                Recommender-Systems             294    \n",
       "4                 Multivariate        Classification             279    \n",
       "..                          ...                   ...             ...   \n",
       "617               Multivariate        Classification             525    \n",
       "618               Multivariate        Classification              50    \n",
       "619                                   Classification               7    \n",
       "620  Multivariate, Time-Series        Classification              16    \n",
       "621                 Univariate            Regression               2    \n",
       "\n",
       "    Number of Instances Number of Attributes   Year  \n",
       "0                 4177                    8   1995   \n",
       "1                48842                   14   1996   \n",
       "2                  798                   38          \n",
       "3                37711                  294   1998   \n",
       "4                  452                  279   1998   \n",
       "..                  ...                  ...    ...  \n",
       "617              75840                  525   2020   \n",
       "618                400                   50   2020   \n",
       "619               1014                    7   2020   \n",
       "620              10129                   16   2021   \n",
       "621               4000                    2   2021   \n",
       "\n",
       "[622 rows x 7 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame from scraped data\n",
    "df = pd.DataFrame({'Name':name,\n",
    "                    'Data Types':typee,\n",
    "                    'Default Task':task,\n",
    "                    'Attribute Types':attribute,\n",
    "                    'Number of Instances':instances,\n",
    "                    'Number of Attributes':attributes,\n",
    "                    'Year':year})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22c092a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
